{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender_submission.csv\n",
      "test.csv\n",
      "train.csv\n"
     ]
    }
   ],
   "source": [
    "path = Path.cwd().parent / 'data'\n",
    "for dirname, _, filenames in os.walk(path):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path / 'train.csv')\n",
    "df_test = pd.read_csv(path / 'test.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Age'], inplace=True)\n",
    "df_test = df_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_data = df['Survived']\n",
    "features = df.drop(columns=['Cabin', 'Embarked', 'Ticket', 'Name', 'Survived'])\n",
    "features_test = df_test.drop(columns=['Cabin', 'Embarked', 'Ticket', 'Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data = pd.get_dummies(features)\n",
    "X_test = pd.get_dummies(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_data, y_train_data, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8, 'min_samples_split': 2, 'n_estimators': 200}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "parameters = {'n_estimators': [100, 150, 200, 250, 300, 350, 400, 450, 500],\n",
    "              'max_depth': [1, 2 , 5, 6, 7, 8, 9],\n",
    "             'min_samples_split': [2,20,200]}\n",
    "clf = GridSearchCV(random_forest, parameters, cv=3, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "sorted(clf.cv_results_.keys())\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.663588</td>\n",
       "      <td>0.027023</td>\n",
       "      <td>0.038868</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 2, 'n_es...</td>\n",
       "      <td>0.811518</td>\n",
       "      <td>0.831579</td>\n",
       "      <td>0.847368</td>\n",
       "      <td>0.830155</td>\n",
       "      <td>0.014670</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1.874004</td>\n",
       "      <td>0.086831</td>\n",
       "      <td>0.081377</td>\n",
       "      <td>0.003550</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_split': 2, 'n_es...</td>\n",
       "      <td>0.821990</td>\n",
       "      <td>0.847368</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.830137</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.829816</td>\n",
       "      <td>0.047780</td>\n",
       "      <td>0.037367</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 2, 'n_es...</td>\n",
       "      <td>0.811518</td>\n",
       "      <td>0.826316</td>\n",
       "      <td>0.847368</td>\n",
       "      <td>0.828401</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1.409829</td>\n",
       "      <td>0.177981</td>\n",
       "      <td>0.061222</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_split': 2, 'n_es...</td>\n",
       "      <td>0.821990</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.828382</td>\n",
       "      <td>0.009711</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1.505306</td>\n",
       "      <td>0.116930</td>\n",
       "      <td>0.087364</td>\n",
       "      <td>0.016279</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>450</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_split': 2, 'n_es...</td>\n",
       "      <td>0.821990</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.828382</td>\n",
       "      <td>0.009711</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.407037</td>\n",
       "      <td>0.081259</td>\n",
       "      <td>0.032485</td>\n",
       "      <td>0.015831</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 200, 'n_...</td>\n",
       "      <td>0.774869</td>\n",
       "      <td>0.784211</td>\n",
       "      <td>0.773684</td>\n",
       "      <td>0.777588</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.300256</td>\n",
       "      <td>0.029965</td>\n",
       "      <td>0.018962</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 200, 'n_...</td>\n",
       "      <td>0.774869</td>\n",
       "      <td>0.784211</td>\n",
       "      <td>0.773684</td>\n",
       "      <td>0.777588</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.358754</td>\n",
       "      <td>0.065276</td>\n",
       "      <td>0.017932</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_split': 200, 'n_...</td>\n",
       "      <td>0.774869</td>\n",
       "      <td>0.784211</td>\n",
       "      <td>0.773684</td>\n",
       "      <td>0.777588</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.325430</td>\n",
       "      <td>0.010469</td>\n",
       "      <td>0.020495</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_split': 200, 'n_...</td>\n",
       "      <td>0.774869</td>\n",
       "      <td>0.784211</td>\n",
       "      <td>0.773684</td>\n",
       "      <td>0.777588</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.357715</td>\n",
       "      <td>0.065348</td>\n",
       "      <td>0.022568</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 200, 'n_...</td>\n",
       "      <td>0.769634</td>\n",
       "      <td>0.778947</td>\n",
       "      <td>0.773684</td>\n",
       "      <td>0.774088</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "137       0.663588      0.027023         0.038868        0.007001   \n",
       "170       1.874004      0.086831         0.081377        0.003550   \n",
       "138       0.829816      0.047780         0.037367        0.000570   \n",
       "168       1.409829      0.177981         0.061222        0.003099   \n",
       "169       1.505306      0.116930         0.087364        0.016279   \n",
       "..             ...           ...              ...             ...   \n",
       "72        0.407037      0.081259         0.032485        0.015831   \n",
       "153       0.300256      0.029965         0.018962        0.002767   \n",
       "126       0.358754      0.065276         0.017932        0.002058   \n",
       "180       0.325430      0.010469         0.020495        0.002278   \n",
       "45        0.357715      0.065348         0.022568        0.003862   \n",
       "\n",
       "     param_max_depth  param_min_samples_split  param_n_estimators  \\\n",
       "137                8                        2                 200   \n",
       "170                9                        2                 500   \n",
       "138                8                        2                 250   \n",
       "168                9                        2                 400   \n",
       "169                9                        2                 450   \n",
       "..               ...                      ...                 ...   \n",
       "72                 5                      200                 100   \n",
       "153                8                      200                 100   \n",
       "126                7                      200                 100   \n",
       "180                9                      200                 100   \n",
       "45                 2                      200                 100   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "137  {'max_depth': 8, 'min_samples_split': 2, 'n_es...           0.811518   \n",
       "170  {'max_depth': 9, 'min_samples_split': 2, 'n_es...           0.821990   \n",
       "138  {'max_depth': 8, 'min_samples_split': 2, 'n_es...           0.811518   \n",
       "168  {'max_depth': 9, 'min_samples_split': 2, 'n_es...           0.821990   \n",
       "169  {'max_depth': 9, 'min_samples_split': 2, 'n_es...           0.821990   \n",
       "..                                                 ...                ...   \n",
       "72   {'max_depth': 5, 'min_samples_split': 200, 'n_...           0.774869   \n",
       "153  {'max_depth': 8, 'min_samples_split': 200, 'n_...           0.774869   \n",
       "126  {'max_depth': 7, 'min_samples_split': 200, 'n_...           0.774869   \n",
       "180  {'max_depth': 9, 'min_samples_split': 200, 'n_...           0.774869   \n",
       "45   {'max_depth': 2, 'min_samples_split': 200, 'n_...           0.769634   \n",
       "\n",
       "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "137           0.831579           0.847368         0.830155        0.014670   \n",
       "170           0.847368           0.821053         0.830137        0.012191   \n",
       "138           0.826316           0.847368         0.828401        0.014710   \n",
       "168           0.842105           0.821053         0.828382        0.009711   \n",
       "169           0.842105           0.821053         0.828382        0.009711   \n",
       "..                 ...                ...              ...             ...   \n",
       "72            0.784211           0.773684         0.777588        0.004708   \n",
       "153           0.784211           0.773684         0.777588        0.004708   \n",
       "126           0.784211           0.773684         0.777588        0.004708   \n",
       "180           0.784211           0.773684         0.777588        0.004708   \n",
       "45            0.778947           0.773684         0.774088        0.003813   \n",
       "\n",
       "     rank_test_score  \n",
       "137                1  \n",
       "170                2  \n",
       "138                3  \n",
       "168                4  \n",
       "169                4  \n",
       "..               ...  \n",
       "72               184  \n",
       "153              184  \n",
       "126              184  \n",
       "180              184  \n",
       "45               189  \n",
       "\n",
       "[189 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_frame = pd.DataFrame(clf.cv_results_)\n",
    "\n",
    "dat_frame.sort_values('mean_test_score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'PassengerId': df_test.PassengerId,'Survived': clf.predict(X_test)})\n",
    "\n",
    "output.to_csv('submission.csv',index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
